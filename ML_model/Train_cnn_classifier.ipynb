{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting original healthy data used to train the TFLite micro model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset live shape: (33630, 6, 100)\n",
      "Dataset live labels shape (33630,)\n",
      "Nan_rows shape:  (246, 3)\n",
      "Number of nan_rows [[10970     0     0]\n",
      " [10970     1     0]\n",
      " [10970     2     0]\n",
      " [10970     3     0]\n",
      " [10970     4     0]\n",
      " [10970     5     0]\n",
      " [23655     0    60]\n",
      " [23655     0    61]\n",
      " [23655     0    62]\n",
      " [23655     0    63]\n",
      " [23655     0    64]\n",
      " [23655     0    65]\n",
      " [23655     0    66]\n",
      " [23655     0    67]\n",
      " [23655     0    68]\n",
      " [23655     0    69]\n",
      " [23655     0    70]\n",
      " [23655     0    71]\n",
      " [23655     0    72]\n",
      " [23655     0    73]\n",
      " [23655     0    74]\n",
      " [23655     0    75]\n",
      " [23655     0    76]\n",
      " [23655     0    77]\n",
      " [23655     0    78]\n",
      " [23655     0    79]\n",
      " [23655     0    80]\n",
      " [23655     0    81]\n",
      " [23655     0    82]\n",
      " [23655     0    83]\n",
      " [23655     0    84]\n",
      " [23655     0    85]\n",
      " [23655     0    86]\n",
      " [23655     0    87]\n",
      " [23655     0    88]\n",
      " [23655     0    89]\n",
      " [23655     0    90]\n",
      " [23655     0    91]\n",
      " [23655     0    92]\n",
      " [23655     0    93]\n",
      " [23655     0    94]\n",
      " [23655     0    95]\n",
      " [23655     0    96]\n",
      " [23655     0    97]\n",
      " [23655     0    98]\n",
      " [23655     0    99]\n",
      " [23655     1    60]\n",
      " [23655     1    61]\n",
      " [23655     1    62]\n",
      " [23655     1    63]\n",
      " [23655     1    64]\n",
      " [23655     1    65]\n",
      " [23655     1    66]\n",
      " [23655     1    67]\n",
      " [23655     1    68]\n",
      " [23655     1    69]\n",
      " [23655     1    70]\n",
      " [23655     1    71]\n",
      " [23655     1    72]\n",
      " [23655     1    73]\n",
      " [23655     1    74]\n",
      " [23655     1    75]\n",
      " [23655     1    76]\n",
      " [23655     1    77]\n",
      " [23655     1    78]\n",
      " [23655     1    79]\n",
      " [23655     1    80]\n",
      " [23655     1    81]\n",
      " [23655     1    82]\n",
      " [23655     1    83]\n",
      " [23655     1    84]\n",
      " [23655     1    85]\n",
      " [23655     1    86]\n",
      " [23655     1    87]\n",
      " [23655     1    88]\n",
      " [23655     1    89]\n",
      " [23655     1    90]\n",
      " [23655     1    91]\n",
      " [23655     1    92]\n",
      " [23655     1    93]\n",
      " [23655     1    94]\n",
      " [23655     1    95]\n",
      " [23655     1    96]\n",
      " [23655     1    97]\n",
      " [23655     1    98]\n",
      " [23655     1    99]\n",
      " [23655     2    60]\n",
      " [23655     2    61]\n",
      " [23655     2    62]\n",
      " [23655     2    63]\n",
      " [23655     2    64]\n",
      " [23655     2    65]\n",
      " [23655     2    66]\n",
      " [23655     2    67]\n",
      " [23655     2    68]\n",
      " [23655     2    69]\n",
      " [23655     2    70]\n",
      " [23655     2    71]\n",
      " [23655     2    72]\n",
      " [23655     2    73]\n",
      " [23655     2    74]\n",
      " [23655     2    75]\n",
      " [23655     2    76]\n",
      " [23655     2    77]\n",
      " [23655     2    78]\n",
      " [23655     2    79]\n",
      " [23655     2    80]\n",
      " [23655     2    81]\n",
      " [23655     2    82]\n",
      " [23655     2    83]\n",
      " [23655     2    84]\n",
      " [23655     2    85]\n",
      " [23655     2    86]\n",
      " [23655     2    87]\n",
      " [23655     2    88]\n",
      " [23655     2    89]\n",
      " [23655     2    90]\n",
      " [23655     2    91]\n",
      " [23655     2    92]\n",
      " [23655     2    93]\n",
      " [23655     2    94]\n",
      " [23655     2    95]\n",
      " [23655     2    96]\n",
      " [23655     2    97]\n",
      " [23655     2    98]\n",
      " [23655     2    99]\n",
      " [23655     3    60]\n",
      " [23655     3    61]\n",
      " [23655     3    62]\n",
      " [23655     3    63]\n",
      " [23655     3    64]\n",
      " [23655     3    65]\n",
      " [23655     3    66]\n",
      " [23655     3    67]\n",
      " [23655     3    68]\n",
      " [23655     3    69]\n",
      " [23655     3    70]\n",
      " [23655     3    71]\n",
      " [23655     3    72]\n",
      " [23655     3    73]\n",
      " [23655     3    74]\n",
      " [23655     3    75]\n",
      " [23655     3    76]\n",
      " [23655     3    77]\n",
      " [23655     3    78]\n",
      " [23655     3    79]\n",
      " [23655     3    80]\n",
      " [23655     3    81]\n",
      " [23655     3    82]\n",
      " [23655     3    83]\n",
      " [23655     3    84]\n",
      " [23655     3    85]\n",
      " [23655     3    86]\n",
      " [23655     3    87]\n",
      " [23655     3    88]\n",
      " [23655     3    89]\n",
      " [23655     3    90]\n",
      " [23655     3    91]\n",
      " [23655     3    92]\n",
      " [23655     3    93]\n",
      " [23655     3    94]\n",
      " [23655     3    95]\n",
      " [23655     3    96]\n",
      " [23655     3    97]\n",
      " [23655     3    98]\n",
      " [23655     3    99]\n",
      " [23655     4    60]\n",
      " [23655     4    61]\n",
      " [23655     4    62]\n",
      " [23655     4    63]\n",
      " [23655     4    64]\n",
      " [23655     4    65]\n",
      " [23655     4    66]\n",
      " [23655     4    67]\n",
      " [23655     4    68]\n",
      " [23655     4    69]\n",
      " [23655     4    70]\n",
      " [23655     4    71]\n",
      " [23655     4    72]\n",
      " [23655     4    73]\n",
      " [23655     4    74]\n",
      " [23655     4    75]\n",
      " [23655     4    76]\n",
      " [23655     4    77]\n",
      " [23655     4    78]\n",
      " [23655     4    79]\n",
      " [23655     4    80]\n",
      " [23655     4    81]\n",
      " [23655     4    82]\n",
      " [23655     4    83]\n",
      " [23655     4    84]\n",
      " [23655     4    85]\n",
      " [23655     4    86]\n",
      " [23655     4    87]\n",
      " [23655     4    88]\n",
      " [23655     4    89]\n",
      " [23655     4    90]\n",
      " [23655     4    91]\n",
      " [23655     4    92]\n",
      " [23655     4    93]\n",
      " [23655     4    94]\n",
      " [23655     4    95]\n",
      " [23655     4    96]\n",
      " [23655     4    97]\n",
      " [23655     4    98]\n",
      " [23655     4    99]\n",
      " [23655     5    60]\n",
      " [23655     5    61]\n",
      " [23655     5    62]\n",
      " [23655     5    63]\n",
      " [23655     5    64]\n",
      " [23655     5    65]\n",
      " [23655     5    66]\n",
      " [23655     5    67]\n",
      " [23655     5    68]\n",
      " [23655     5    69]\n",
      " [23655     5    70]\n",
      " [23655     5    71]\n",
      " [23655     5    72]\n",
      " [23655     5    73]\n",
      " [23655     5    74]\n",
      " [23655     5    75]\n",
      " [23655     5    76]\n",
      " [23655     5    77]\n",
      " [23655     5    78]\n",
      " [23655     5    79]\n",
      " [23655     5    80]\n",
      " [23655     5    81]\n",
      " [23655     5    82]\n",
      " [23655     5    83]\n",
      " [23655     5    84]\n",
      " [23655     5    85]\n",
      " [23655     5    86]\n",
      " [23655     5    87]\n",
      " [23655     5    88]\n",
      " [23655     5    89]\n",
      " [23655     5    90]\n",
      " [23655     5    91]\n",
      " [23655     5    92]\n",
      " [23655     5    93]\n",
      " [23655     5    94]\n",
      " [23655     5    95]\n",
      " [23655     5    96]\n",
      " [23655     5    97]\n",
      " [23655     5    98]\n",
      " [23655     5    99]]\n",
      "nan_rows shape:  (0, 3)\n",
      "number of nan_rows:  []\n",
      "Dataset live shape:  (33628, 6, 100)\n",
      "Dataset live labels shape:  (33628,)\n"
     ]
    }
   ],
   "source": [
    "folder = \"C:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/LiveData/*\"\n",
    "\n",
    "# get all files in folder\n",
    "files = glob.glob(folder + '*.csv')\n",
    "\n",
    "dataset_live_list = []\n",
    "\n",
    "# num_files = 0\n",
    "for file in files:\n",
    "    # if (num_files == 20):\n",
    "    #     break\n",
    "    \n",
    "    # num_files += 1\n",
    "    # read data from file\n",
    "    data = pd.read_csv(file, header=None)\n",
    "    \n",
    "    # remove first column\n",
    "    data = data.drop(data.columns[0], axis=1)\n",
    "    \n",
    "    # next 6 columns are the vibration data\n",
    "    data = data.iloc[:, 0:6].values  # Convert to numpy array\n",
    "\n",
    "    # Calculate the number of chunks (100-row segments)\n",
    "    num_chunks = data.shape[0] // 100\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        chunk = data[i*100:(i+1)*100, :]\n",
    "        dataset_live_list.append(chunk.transpose()[np.newaxis, :])\n",
    "\n",
    "# Convert list to numpy array\n",
    "dataset_live = np.concatenate(dataset_live_list, axis=0)\n",
    "\n",
    "print(\"Dataset live shape:\", dataset_live.shape)\n",
    "\n",
    "# label datasets as \"LiveData\"\n",
    "\n",
    "dataset_live_labels = np.full((dataset_live.shape[0]), 'LiveData')\n",
    "\n",
    "print(\"Dataset live labels shape\", dataset_live_labels.shape)\n",
    "\n",
    "\n",
    "# remove NAN rows along with their corresponding labels\n",
    "\n",
    "# find the rows with NAN\n",
    "nan_rows = np.argwhere(np.isnan(dataset_live))\n",
    "print(\"Nan_rows shape: \", nan_rows.shape)\n",
    "print(\"Number of nan_rows\", nan_rows)\n",
    "\n",
    "# remove the rows with NAN\n",
    "dataset_live = np.delete(dataset_live, nan_rows[:, 0], axis=0)\n",
    "dataset_live_labels = np.delete(dataset_live_labels, nan_rows[:, 0], axis=0)\n",
    "\n",
    "# check that there are no more NAN rows\n",
    "nan_rows = np.argwhere(np.isnan(dataset_live))\n",
    "print(\"nan_rows shape: \" ,nan_rows.shape)\n",
    "print(\"number of nan_rows: \", nan_rows)\n",
    "\n",
    "# check that the shapes are the same\n",
    "print(\"Dataset live shape: \", dataset_live.shape)\n",
    "print(\"Dataset live labels shape: \", dataset_live_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting data collected from RPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-12T16-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-12T17-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-12T18-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-12T19-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-12T20-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-12T21-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-12T22-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-12T23-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T00-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T01-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T02-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T03-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T04-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T05-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T06-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T07-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T08-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T09-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T10-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy2\\2023-09-13T11-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-25T19-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-25T20-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-25T21-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-25T22-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-25T23-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T00-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T01-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T02-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T03-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T04-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T05-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T06-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T07-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T08-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T09-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T10-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T11-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T12-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T13-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Healthy3\\2023-09-26T14-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-18T18-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-18T19-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-18T20-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-18T21-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-18T22-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-18T23-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T00-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T01-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T02-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T03-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T04-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T05-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T06-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T07-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T08-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T09-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T10-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T11-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T12-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose2\\2023-09-19T13-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-28T15-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-28T16-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-28T17-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-28T18-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-28T19-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-28T20-00-02.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-28T21-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-28T22-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-28T23-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-29T00-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-29T01-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-29T02-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-29T03-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-29T04-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-29T05-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-29T06-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-29T07-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-29T08-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-29T09-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Loose3\\2023-09-29T10-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-05T16-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-05T17-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-05T18-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-05T19-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-05T20-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-05T21-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-05T22-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-05T23-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T00-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T01-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T02-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T03-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T04-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T05-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T06-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T07-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T08-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T09-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T10-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation\\2023-09-06T11-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-06T16-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-06T17-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-06T18-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-06T19-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-06T20-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-06T21-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-06T22-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-06T23-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T00-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T01-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T02-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T03-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T04-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T05-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T06-00-01.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T07-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T08-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T09-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T10-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation2\\2023-09-07T11-00-00.txt\n",
      "c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/Cavitation3\\2023-09-22T15-00-00.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jared\\Desktop\\EG3301R_Repos\\TFLite\\ML_model\\Train_cnn_classifier.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jared/Desktop/EG3301R_Repos/TFLite/ML_model/Train_cnn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     num_files \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jared/Desktop/EG3301R_Repos/TFLite/ML_model/Train_cnn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mprint\u001b[39m(file)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jared/Desktop/EG3301R_Repos/TFLite/ML_model/Train_cnn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     data_segment \u001b[39m=\u001b[39m newDataReader(file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jared/Desktop/EG3301R_Repos/TFLite/ML_model/Train_cnn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     Dataset\u001b[39m.\u001b[39mappend(data_segment)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jared/Desktop/EG3301R_Repos/TFLite/ML_model/Train_cnn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m Dataset_np \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(Dataset, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)  \u001b[39m# shape becomes (9, total_n_for_this_label, 1000)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\jared\\Desktop\\EG3301R_Repos\\TFLite\\ML_model\\Train_cnn_classifier.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jared/Desktop/EG3301R_Repos/TFLite/ML_model/Train_cnn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnewDataReader\u001b[39m(datapath):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jared/Desktop/EG3301R_Repos/TFLite/ML_model/Train_cnn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(datapath, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jared/Desktop/EG3301R_Repos/TFLite/ML_model/Train_cnn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         lines \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39;49mreadlines()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jared/Desktop/EG3301R_Repos/TFLite/ML_model/Train_cnn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     data_blocks \u001b[39m=\u001b[39m []  \u001b[39m# to store individual data blocks of 1000 lines each\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jared/Desktop/EG3301R_Repos/TFLite/ML_model/Train_cnn_classifier.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jared\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1252.py:22\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mIncrementalDecoder\u001b[39;00m(codecs\u001b[39m.\u001b[39mIncrementalDecoder):\n\u001b[1;32m---> 22\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     23\u001b[0m         \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39mcharmap_decode(\u001b[39minput\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors,decoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def newDataReader(datapath):\n",
    "    \n",
    "    with open(datapath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    data_blocks = []  # to store individual data blocks of 1000 lines each\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        if '----' in line:\n",
    "            i += 1\n",
    "            continue\n",
    "        else:\n",
    "            start = i\n",
    "            # Find the end of this block (either another dash line or end of file)\n",
    "            while i < len(lines) and '----' not in lines[i]:\n",
    "                i += 1\n",
    "            end = i\n",
    "            \n",
    "            block = lines[start:end]\n",
    "            data = [list(map(float, item.split(','))) for item in block if ',' in item]  # convert string to list of floats\n",
    "            \n",
    "            # Check the length of data, adjust and log if necessary\n",
    "            if len(data) < 1000:\n",
    "                padding = [[0.0] * 9 for _ in range(1000 - len(data))]\n",
    "                data.extend(padding)\n",
    "                print(f\"Data block starting at line {start} has less than 1000 lines. Padding with zeros.\")\n",
    "            elif len(data) > 1000:\n",
    "                data = data[:1000]\n",
    "                print(f\"Data block starting at line {start} has more than 1000 lines. Truncating to 1000.\")\n",
    "            \n",
    "            data_blocks.append(data)\n",
    "\n",
    "    # Convert list of data blocks into a 3D numpy array\n",
    "    datasets_array = np.array(data_blocks)\n",
    "    \n",
    "    return datasets_array\n",
    "\n",
    "\n",
    "folder = \"c:/Users/jared/Desktop/EG3301R_Repos/collected_data/datacollect/\"\n",
    "\n",
    "dataset1_label = [\"Healthy2\", \"Healthy3\", \"Loose2\", \"Loose3\", \"Cavitation\", \"Cavitation2\", \"Cavitation3\", \"Cavitation10\"]\n",
    "\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "for label in dataset1_label:\n",
    "    files = glob.glob(folder + label + \"/*\")\n",
    "    Dataset = []\n",
    "    num_files = 0\n",
    "    for file in files:\n",
    "        if (num_files == 20):\n",
    "            break\n",
    "        \n",
    "        num_files += 1\n",
    "        print(file)\n",
    "        data_segment = newDataReader(file)\n",
    "        Dataset.append(data_segment)\n",
    "    Dataset_np = np.concatenate(Dataset, axis=0)  # shape becomes (9, total_n_for_this_label, 1000)\n",
    "    Dataset_np = np.transpose(Dataset_np, (0, 2, 1))  # shape becomes (total_n_for_this_label, 9, 1000)\n",
    "\n",
    "    # Append to main data list\n",
    "    all_data.append(Dataset_np)\n",
    "    \n",
    "    # Create and append labels for this data\n",
    "    labels_for_this_data = [label] * Dataset_np.shape[0]  # repeat the label 'total_n_for_this_label' times\n",
    "    all_labels.extend(labels_for_this_data)\n",
    "\n",
    "# remove last 3 columns\n",
    "all_data = [data[:, :6, :] for data in all_data]\n",
    "\n",
    "# Combine all data segments\n",
    "all_data_np = np.concatenate(all_data, axis=0)  # shape: (total_n, 9, 1000)\n",
    "\n",
    "# Convert all labels to numpy array for consistency\n",
    "all_labels_np = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44065, 6, 1000)\n",
      "(44065,)\n"
     ]
    }
   ],
   "source": [
    "print(all_data_np.shape)  # This should give (total_n, 9, 1000)\n",
    "print(all_labels_np.shape)  # This should give (total_n,)\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(474278, 6, 100)\n",
      "(474278,)\n"
     ]
    }
   ],
   "source": [
    "# to convert to 100 sized segments\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for sample in all_data_np:\n",
    "    for i in range(0, 1000, 100):\n",
    "        new_data.append(sample[:, i:i+100])\n",
    "\n",
    "# Convert new_data list to numpy array\n",
    "all_data_np_reshaped = np.array(new_data)\n",
    "\n",
    "# Adjust labels\n",
    "all_labels_np_reshaped = np.repeat(all_labels_np, 10)\n",
    "\n",
    "# erase new_data\n",
    "del new_data\n",
    "\n",
    "# add live data to the end of the dataset\n",
    "\n",
    "all_data_np_reshaped = np.concatenate((all_data_np_reshaped, dataset_live), axis=0)\n",
    "all_labels_np_reshaped = np.concatenate((all_labels_np_reshaped, dataset_live_labels), axis=0)\n",
    "\n",
    "print(all_data_np_reshaped.shape)\n",
    "print(all_labels_np_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data for each axis for the first 6 axes from -1 to 1\n",
    "# the last 3 axes are already in the range of 0 to 1\n",
    "# use MinMaxScaler from sklearnW\n",
    "data_to_use = all_data_np_reshaped\n",
    "labels_to_use = all_labels_np_reshaped\n",
    "\n",
    "# clear reshaped data\n",
    "del all_data_np_reshaped\n",
    "del all_labels_np_reshaped\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "for i in range(6):\n",
    "    data_to_use[:, i, :] = scaler.fit_transform(data_to_use[:, i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the true labels, Healthy, Healthy2, Healthy3 are all Healthy, Loose, Loose2 are all Loose, Cavitation, Cavitation2, Cavitation3 are all Cavitation\n",
    "true_labels = labels_to_use.copy()\n",
    "\n",
    "# true_labels[true_labels == \"Healthy2\"] = \"Healthynew\"\n",
    "# true_labels[true_labels == \"Healthy3\"] = \"Healthynew\"\n",
    "\n",
    "# true_labels[true_labels == \"Loose2\"] = \"Loosenew\"\n",
    "# true_labels[true_labels == \"Loose3\"] = \"Loosenew\"\n",
    "\n",
    "# true_labels[true_labels == \"Cavitation2\"] = \"Cavitation\"\n",
    "# true_labels[true_labels == \"Cavitation3\"] = \"Cavitation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(474278, 600)\n",
      "(474278, 600)\n",
      "(474278,)\n"
     ]
    }
   ],
   "source": [
    "# choose one axis so that we can do ml on it\n",
    "import seaborn as sns\n",
    "\n",
    "# all_data_oneaxis = all_data_np[:, 0, :]  # shape: (total_n, 1000)\n",
    "\n",
    "# create new dataframe that consists of the combination of the first 100 data points of each segment for the first 6 segments resulting in (total_n, 600)\n",
    "all_data_concat = np.concatenate((data_to_use[:, 0,:100], data_to_use[:, 1, :100], data_to_use[:, 2, :100], data_to_use[:, 3, :100], data_to_use[:, 4, :100], data_to_use[:, 5, :100]), axis=1)\n",
    "print(all_data_concat.shape)\n",
    "\n",
    "\n",
    "# remove Healthy and Loose from the data\n",
    "\n",
    "# all_data_concat = all_data_concat[true_labels != \"Healthy\"]\n",
    "# true_labels = true_labels[true_labels != \"Healthy\"]\n",
    "# all_data_concat = all_data_concat[true_labels != \"Loose\"]\n",
    "# true_labels = true_labels[true_labels != \"Loose\"]\n",
    "\n",
    "print(all_data_concat.shape)\n",
    "print(true_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing data for 1D CNN classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS CELL TO BALANCE THE DATA\n",
    "\n",
    "# want to make sure data is balanced, cut the data so that each label has the same number of data points\n",
    "# first find the label with the least number of data points\n",
    "unique, counts = np.unique(true_labels, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)\n",
    "\n",
    "# now, cut the data so that each label has the same number of data points while also spreading the data points out evenly\n",
    "# first, find the number of data points to cut\n",
    "min_count = min(counts)\n",
    "print(min_count)\n",
    "\n",
    "# now, cut the data\n",
    "all_data_concat_cut = np.empty((0, 600))\n",
    "true_labels_cut = np.empty((0))\n",
    "\n",
    "# cut such that the data is spread out evenly\n",
    "for i in range(len(unique)):\n",
    "    toadd = all_data_concat[true_labels == unique[i]]\n",
    "    toadd = toadd[::(int)(len(toadd)/min_count)]\n",
    "    toadd = toadd[:min_count]\n",
    "    all_data_concat_cut = np.concatenate((all_data_concat_cut, toadd), axis=0)\n",
    "    toadd = true_labels[true_labels == unique[i]]\n",
    "    toadd = toadd[::(int)(len(toadd)/min_count)]\n",
    "    toadd = toadd[:min_count]\n",
    "    true_labels_cut = np.concatenate((true_labels_cut, toadd), axis=0)\n",
    "\n",
    "print(all_data_concat_cut.shape)\n",
    "print(true_labels_cut.shape)\n",
    "\n",
    "unique, counts = np.unique(true_labels_cut, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)\n",
    "\n",
    "all_data_concat = all_data_concat_cut\n",
    "true_labels = true_labels_cut\n",
    "\n",
    "all_data_concat_cut = None\n",
    "true_labels_cut = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data for each label and segment\n",
    "for i in range(len(unique)):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.title(unique[i])\n",
    "    plt.plot(all_data_concat[true_labels == unique[i], :][0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201768, 600)\n",
      "(201768, 3)\n",
      "(100884, 600)\n",
      "(100884, 3)\n",
      "['Cavitation' 'Healthy' 'Loose']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# clear the tensorflow runtime\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "# disable gpu for training\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "# enable gpu for training\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "X = all_data_concat\n",
    "Y = true_labels\n",
    "\n",
    "X_training = X[np.isin(Y, ['Loose2', 'Cavitation2', 'Cavitation', 'Healthy3', 'Healthy2', 'Cavitation3'])]\n",
    "Y_training = Y[np.isin(Y, ['Loose2', 'Cavitation2', 'Cavitation', 'Healthy3', 'Healthy2', 'Cavitation3'])]\n",
    "\n",
    "# change the labels from Healthy2 --> Healthy, Loose2 --> Loose, Cavitation2 --> Cavitation\n",
    "Y_training[Y_training == \"Healthy2\"] = \"Healthy\"\n",
    "Y_training[Y_training == \"Loose2\"] = \"Loose\"\n",
    "Y_training[Y_training == \"Cavitation2\"] = \"Cavitation\"\n",
    "\n",
    "Y_training[Y_training == \"Healthy3\"] = \"Healthy\"\n",
    "# Y_training[Y_training == \"Loose3\"] = \"Loose\"\n",
    "Y_training[Y_training == \"Cavitation3\"] = \"Cavitation\"\n",
    "\n",
    "\n",
    "# # take out Healthy3, Loose3, Cavitation3 as hidden data\n",
    "# X_hidden = X[np.isin(Y, ['Healthy3', 'Loose3', 'Cavitation3'])]\n",
    "# Y_hidden = Y[np.isin(Y, ['Healthy3', 'Loose3', 'Cavitation3'])]\n",
    "\n",
    "# # change the labels from Healthy3 --> Healthy, Loose3 --> Loose, Cavitation3 --> Cavitation\n",
    "# Y_hidden[Y_hidden == \"Healthy3\"] = \"Healthy\"\n",
    "# Y_hidden[Y_hidden == \"Loose3\"] = \"Loose\"\n",
    "# Y_hidden[Y_hidden == \"Cavitation3\"] = \"Cavitation\"\n",
    "\n",
    "# take out Healthy3, Loose3, Cavitation3 as hidden data\n",
    "X_hidden = X[np.isin(Y, ['LiveData', 'Loose3', 'Cavitation10'])]\n",
    "Y_hidden = Y[np.isin(Y, ['LiveData', 'Loose3', 'Cavitation10'])]\n",
    "\n",
    "# change the labels from LiveData --> Healthy\n",
    "Y_hidden[Y_hidden == \"LiveData\"] = \"Healthy\"\n",
    "Y_hidden[Y_hidden == \"Loose3\"] = \"Loose\"\n",
    "Y_hidden[Y_hidden == \"Cavitation10\"] = \"Cavitation\"\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_training)\n",
    "encoded_Y = encoder.transform(Y_training)\n",
    "OHE_Y_training = to_categorical(encoded_Y)\n",
    "encoded_Y_hidden = encoder.transform(Y_hidden)\n",
    "OHE_Y_hidden = to_categorical(encoded_Y_hidden)\n",
    "\n",
    "print(X_training.shape)\n",
    "print(OHE_Y_training.shape)\n",
    "print(X_hidden.shape)\n",
    "print(OHE_Y_hidden.shape)\n",
    "print(encoder.classes_)\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "# print(tf.config.list_logical_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, OHE_Y_training, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_82 (Conv1D)          (None, 551, 16)           816       \n",
      "                                                                 \n",
      " conv1d_83 (Conv1D)          (None, 527, 8)            3208      \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPooli  (None, 131, 8)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 1048)              0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 32)                33568     \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37691 (147.23 KB)\n",
      "Trainable params: 37691 (147.23 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "600\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 600)]             0         \n",
      "                                                                 \n",
      " sequential_44 (Sequential)  (None, 1048)              4024      \n",
      "                                                                 \n",
      " sequential_45 (Sequential)  (None, 600)               44176     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48200 (188.28 KB)\n",
      "Trainable params: 48200 (188.28 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv1D, MaxPooling1D, UpSampling1D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# set early stopping criteria\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "no_classes = len(encoder.classes_)\n",
    "\n",
    "# 1d convolutional classifier\n",
    "cnn_classifier_model = Sequential()\n",
    "cnn_classifier_model.add(Conv1D(filters=16, kernel_size=50, activation='elu', input_shape=(X_train.shape[1], 1)))\n",
    "# cnn_classifier_model.add(Dropout(0.2))\n",
    "cnn_classifier_model.add(Conv1D(filters=8, kernel_size=25, activation='elu'))\n",
    "# cnn_classifier_model.add(Dropout(0.2))\n",
    "\n",
    "cnn_classifier_model.add(MaxPooling1D(pool_size=4))\n",
    "cnn_classifier_model.add(Flatten())\n",
    "cnn_classifier_model.add(Dense(32, activation='elu'))\n",
    "# cnn_classifier_model.add(Dropout(0.2))\n",
    "cnn_classifier_model.add(Dense(no_classes, activation='softmax'))\n",
    "\n",
    "cnn_classifier_model.summary()\n",
    "\n",
    "cnn_classifier_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# For early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "48/48 [==============================] - 93s 2s/step - loss: 0.7327 - accuracy: 0.6685 - val_loss: 0.3323 - val_accuracy: 0.8757\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 86s 2s/step - loss: 0.2364 - accuracy: 0.9108 - val_loss: 0.1894 - val_accuracy: 0.9285\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 91s 2s/step - loss: 0.1674 - accuracy: 0.9360 - val_loss: 0.1540 - val_accuracy: 0.9420\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 89s 2s/step - loss: 0.1421 - accuracy: 0.9454 - val_loss: 0.1290 - val_accuracy: 0.9515\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 86s 2s/step - loss: 0.1179 - accuracy: 0.9560 - val_loss: 0.1197 - val_accuracy: 0.9555\n"
     ]
    }
   ],
   "source": [
    "history_cnn_classifier = cnn_classifier_model.fit(X_train,\n",
    "                                                    y_train,\n",
    "                                                    batch_size=3000,\n",
    "                                                    epochs=5,\n",
    "                                                    verbose=1,\n",
    "                                                    shuffle=True,\n",
    "                                                    callbacks=[es],\n",
    "                                                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1892/1892 [==============================] - 10s 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Cavitation       0.97      0.99      0.98     30163\n",
      "     Healthy       0.99      0.96      0.97     20128\n",
      "       Loose       1.00      1.00      1.00     10240\n",
      "\n",
      "    accuracy                           0.98     60531\n",
      "   macro avg       0.99      0.98      0.99     60531\n",
      "weighted avg       0.98      0.98      0.98     60531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inv_Transform_result(y_pred, enc):\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    y_pred = enc.inverse_transform(y_pred)\n",
    "    return y_pred\n",
    "\n",
    "y_pred = cnn_classifier_model.predict(X_test)\n",
    "\n",
    "y_pred = inv_Transform_result(y_pred, encoder)\n",
    "y_compare = inv_Transform_result(y_test, encoder)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "cm = confusion_matrix(y_compare, y_pred, labels=encoder.classes_)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "f = sns.heatmap(cm, annot=True, xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "\n",
    "# confusion matrix with percentages\n",
    "\n",
    "plt.show()\n",
    "\n",
    "report = classification_report(y_compare, y_pred, labels=encoder.classes_)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3153/3153 [==============================] - 17s 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Cavitation       0.96      1.00      0.98     33628\n",
      "     Healthy       0.86      0.89      0.88     33628\n",
      "       Loose       0.93      0.86      0.89     33628\n",
      "\n",
      "    accuracy                           0.92    100884\n",
      "   macro avg       0.92      0.92      0.92    100884\n",
      "weighted avg       0.92      0.92      0.92    100884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now test with the hidden data\n",
    "\n",
    "y_pred = cnn_classifier_model.predict(X_hidden)\n",
    "\n",
    "y_pred = inv_Transform_result(y_pred, encoder)\n",
    "y_comp = inv_Transform_result(OHE_Y_hidden, encoder)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "cm = confusion_matrix(y_comp, y_pred, labels=encoder.classes_)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "f = sns.heatmap(cm, annot=True, xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.show()\n",
    "\n",
    "report = classification_report(y_comp, y_pred, labels=encoder.classes_)\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jared\\AppData\\Local\\Temp\\tmp9qhtmgak\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jared\\AppData\\Local\\Temp\\tmp9qhtmgak\\assets\n",
      "c:\\Users\\jared\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45688"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tinymlgen import port\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# def cnn_representative_dataset():\n",
    "#     for val in X_test:\n",
    "#         val = np.expand_dims(val, axis=1)\n",
    "#         yield [np.array(val, dtype=np.float32)]\n",
    "        \n",
    "def cnn_representative_dataset():\n",
    "  for data in tf.data.Dataset.from_tensor_slices(X_test).batch(1).take(100):\n",
    "    # Model has only one input so each data point has one element.\n",
    "    data = np.expand_dims(data, axis=-1)\n",
    "    yield [tf.dtypes.cast(data, tf.float32)]\n",
    "\n",
    "# def cnn_representative_dataset():\n",
    "#     for data in tf.data.Dataset.from_tensor_slices(X_test).batch(1).take(1000):\n",
    "#         yield [tf.dtypes.cast(data, tf.float32)]   \n",
    "\n",
    "# Full integer quantization for healthy2 data (Y-axis)\n",
    "fullint_converter_cnn = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "fullint_converter_cnn.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "fullint_converter_cnn.representative_dataset = cnn_representative_dataset\n",
    "fullint_tflite_model_cnn = fullint_converter_cnn.convert()\n",
    "\n",
    "# Save the models\n",
    "open(\"cnn_fullint_quantized.tflite\", \"wb\").write(fullint_tflite_model_cnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing data for 2D CNN classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 2d convolutional autoencoder\n",
    "# first we need to preprocess the data to be 2d\n",
    "\n",
    "# using X and Y from above\n",
    "\n",
    " \n",
    " # USE THIS CELL TO BALANCE THE DATA\n",
    "\n",
    "# want to make sure data is balanced, cut the data so that each label has the same number of data points\n",
    "# first find the label with the least number of data points\n",
    "unique, counts = np.unique(true_labels, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)\n",
    "\n",
    "# now, cut the data so that each label has the same number of data points while also spreading the data points out evenly\n",
    "# first, find the number of data points to cut\n",
    "min_count = min(counts)\n",
    "print(min_count)\n",
    "\n",
    "# now, cut the data\n",
    "all_data_concat_cut = np.empty((0, 576))\n",
    "true_labels_cut = np.empty((0))\n",
    "\n",
    "# cut such that the data is spread out evenly\n",
    "for i in range(len(unique)):\n",
    "    toadd = all_data_concat[true_labels == unique[i]]\n",
    "    toadd = toadd[::(int)(len(toadd)/min_count)]\n",
    "    toadd = toadd[:min_count]\n",
    "    all_data_concat_cut = np.concatenate((all_data_concat_cut, toadd), axis=0)\n",
    "    toadd = true_labels[true_labels == unique[i]]\n",
    "    toadd = toadd[::(int)(len(toadd)/min_count)]\n",
    "    toadd = toadd[:min_count]\n",
    "    true_labels_cut = np.concatenate((true_labels_cut, toadd), axis=0)\n",
    "\n",
    "print(all_data_concat_cut.shape)\n",
    "print(true_labels_cut.shape)\n",
    "\n",
    "unique, counts = np.unique(true_labels_cut, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)\n",
    "\n",
    "all_data_concat = all_data_concat_cut\n",
    "true_labels = true_labels_cut\n",
    "\n",
    "all_data_concat_cut = None\n",
    "true_labels_cut = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# reshape the data to be (n, 24, 24, 1)\n",
    "X = all_data_concat.reshape(all_data_concat.shape[0], 24, 24, 1)\n",
    "Y = true_labels\n",
    "\n",
    "X_training = X[np.isin(Y, ['Loose2','Cavitation', 'Cavitation2', 'Healthy3', 'Healthy2', 'Cavitation3'])]\n",
    "Y_training = Y[np.isin(Y, ['Loose2','Cavitation', 'Cavitation2', 'Healthy3', 'Healthy2', 'Cavitation3'])]\n",
    "\n",
    "# change the labels from Healthy2 --> Healthy, Loose2 --> Loose, Cavitation2 --> Cavitation\n",
    "Y_training[Y_training == \"Healthy2\"] = \"Healthy\"\n",
    "Y_training[Y_training == \"Loose2\"] = \"Loose\"\n",
    "Y_training[Y_training == \"Cavitation2\"] = \"Cavitation\"\n",
    "\n",
    "Y_training[Y_training == \"Healthy3\"] = \"Healthy\"\n",
    "# Y_training[Y_training == \"Loose3\"] = \"Loose\"\n",
    "Y_training[Y_training == \"Cavitation3\"] = \"Cavitation\"\n",
    "\n",
    "\n",
    "# # take out Healthy3, Loose3, Cavitation3 as hidden data\n",
    "# X_hidden = X[np.isin(Y, ['Healthy3', 'Loose3', 'Cavitation3'])]\n",
    "# Y_hidden = Y[np.isin(Y, ['Healthy3', 'Loose3', 'Cavitation3'])]\n",
    "\n",
    "# # change the labels from Healthy3 --> Healthy, Loose3 --> Loose, Cavitation3 --> Cavitation\n",
    "# Y_hidden[Y_hidden == \"Healthy3\"] = \"Healthy\"\n",
    "# Y_hidden[Y_hidden == \"Loose3\"] = \"Loose\"\n",
    "# Y_hidden[Y_hidden == \"Cavitation3\"] = \"Cavitation\"\n",
    "\n",
    "# take out Healthy3, Loose3, Cavitation3 as hidden data\n",
    "X_hidden = X[np.isin(Y, ['LiveData', 'Loose3', 'Cavitation10'])]\n",
    "Y_hidden = Y[np.isin(Y, ['LiveData', 'Loose3', 'Cavitation10'])]\n",
    "\n",
    "# change the labels from LiveData --> Healthy\n",
    "Y_hidden[Y_hidden == \"LiveData\"] = \"Healthy\"\n",
    "Y_hidden[Y_hidden == \"Loose3\"] = \"Loose\"\n",
    "Y_hidden[Y_hidden == \"Cavitation10\"] = \"Cavitation\"\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_training)\n",
    "encoded_Y = encoder.transform(Y_training)\n",
    "OHE_Y_training = to_categorical(encoded_Y)\n",
    "encoded_Y_hidden = encoder.transform(Y_hidden)\n",
    "OHE_Y_hidden = to_categorical(encoded_Y_hidden)\n",
    "\n",
    "print(X_training.shape)\n",
    "print(OHE_Y_training.shape)\n",
    "print(X_hidden.shape)\n",
    "print(OHE_Y_hidden.shape)\n",
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imread\n",
    "\n",
    "# visualize random 5 images from each class\n",
    "\n",
    "# first, get the indices of the first 5 images from each class\n",
    "indices = []\n",
    "for i in range(len(encoder.classes_)):\n",
    "    indices.append(np.argwhere(Y_training == encoder.classes_[i])[:5])\n",
    "\n",
    "# now, plot the images using grayscale\n",
    "fig, ax = plt.subplots(len(encoder.classes_), 5, figsize=(20, 20))\n",
    "for i in range(len(encoder.classes_)):\n",
    "    for j in range(5):\n",
    "        ax[i, j].imshow(X_training[indices[i][j][0], :, :, 0])\n",
    "        ax[i, j].set_title(encoder.classes_[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, OHE_Y_training, test_size=0.25, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "no_classes = len(encoder.classes_)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=12, kernel_size=(3, 3), activation='elu', input_shape=(24, 24, 1), padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='elu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='elu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(no_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping criteria\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=3000,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[es],\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the validation and training accuracy, and loss\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on test data and draw confusion matrix\n",
    "\n",
    "def inv_Transform_result(y_pred, enc):\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    y_pred = enc.inverse_transform(y_pred)\n",
    "    return y_pred\n",
    "\n",
    "# for 2d convolutional autoencoder\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = inv_Transform_result(y_pred, encoder)\n",
    "y_compare = inv_Transform_result(y_test, encoder)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "cm = confusion_matrix(y_compare, y_pred, labels=encoder.classes_)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "f = sns.heatmap(cm, annot=True, xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "\n",
    "# confusion matrix with percentages\n",
    "\n",
    "plt.show()\n",
    "\n",
    "report = classification_report(y_compare, y_pred, labels=encoder.classes_)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now test with the hidden data\n",
    "\n",
    "# for 2d convolutional autoencoder\n",
    "y_pred = model.predict(X_hidden)\n",
    "\n",
    "y_pred = inv_Transform_result(y_pred, encoder)\n",
    "y_comp = inv_Transform_result(OHE_Y_hidden, encoder)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "cm = confusion_matrix(y_comp, y_pred, labels=encoder.classes_)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "f = sns.heatmap(cm, annot=True, xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.show()\n",
    "\n",
    "report = classification_report(y_comp, y_pred, labels=encoder.classes_)\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to tflite model to .cc to be loaded into ESP32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy paste the following lines to run on bash cmdline\n",
    "\n",
    "xxd -i Original_healthy_model_fullint_quantized.tflite > Original_healthy_model_fullint_quantized.cc  \n",
    "xxd -i Healthy2_model_fullint_quantized.tflite > Healthy2_model_fullint_quantized.cc  \n",
    "xxd -i Healthy3_model_fullint_quantized.tflite > Healthy3_model_fullint_quantized.cc\n",
    "xxd -i cnn_fullint_quantized.tflite > cnn_fullint_quantized.cc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluating TFLite micro models against the test data\n",
    "def evaluate_model_y_axis(interpreter, dataset, calculated_threshold):\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    num_test_samples = dataset.shape[0]\n",
    "    # print(\"Dataset shape: \", dataset.shape)\n",
    "\n",
    "    # Run predictions on every set in the \"test\" dataset.\n",
    "    reconstructed_data = []\n",
    "    for i in range(num_test_samples):\n",
    "\n",
    "        # Pre-processing the data to fit it with the model's input.\n",
    "        input_data = np.array(dataset[i], dtype=np.float32)\n",
    "        # print(\"Input data shape:\", input_data.shape)\n",
    "        input_data = np.expand_dims(input_data, axis=0)\n",
    "        # print(\"Input data shape after expand_dims:\", input_data.shape)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        reconstructed_data.append(output_data[0])\n",
    "\n",
    "    # Convert to numpy array from list for easier comparison\n",
    "    reconstructed_data = np.array(reconstructed_data)\n",
    "\n",
    "    mse = np.mean(np.power(dataset - reconstructed_data, 2), axis=1)\n",
    "\n",
    "    anorm_count = 0\n",
    "    for i in range(num_test_samples):\n",
    "        if mse[i] > calculated_threshold:\n",
    "            anorm_count += 1\n",
    "    \n",
    "    return np.array(reconstructed_data), mse, anorm_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the CNN model (6 axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating CNN model using test data:\n",
      "Number of correct predictions:  59419\n",
      "Number of wrong predictions:  1112\n",
      "Model accuracy is 98.16% (Number of test samples=60531)\n",
      "Evaluating CNN model using hidden data:\n",
      "Number of correct predictions:  92383\n",
      "Number of wrong predictions:  8501\n",
      "Model accuracy is 91.57% (Number of test samples=100884)\n"
     ]
    }
   ],
   "source": [
    "cnn_interpreter = tf.lite.Interpreter(model_path='cnn_fullint_quantized.tflite')\n",
    "cnn_interpreter.allocate_tensors()\n",
    "cnn_input_details = cnn_interpreter.get_input_details()[0]\n",
    "cnn_output_details = cnn_interpreter.get_output_details()[0]\n",
    "\n",
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_file, y_test_indices, X_test, y_test):\n",
    "  predictions = np.zeros((len(y_test_indices),), dtype=int)\n",
    "  for i, y_test_index in enumerate(y_test_indices):\n",
    "    test_image = X_test[y_test_index]\n",
    "    test_label = y_test[y_test_index]\n",
    "\n",
    "    # Add a new dimension to the input tensor to match the expected shape\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    test_image = np.expand_dims(test_image, axis=-1)\n",
    "    test_image = test_image.astype(cnn_input_details[\"dtype\"])\n",
    "\n",
    "    cnn_interpreter.set_tensor(cnn_input_details[\"index\"], test_image)\n",
    "    cnn_interpreter.invoke()\n",
    "    output = cnn_interpreter.get_tensor(cnn_output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions\n",
    "\n",
    "## Helper function to test the models on one sample\n",
    "def test_model(tflite_file, y_test_index, X_test, y_test):\n",
    "  predictions = run_tflite_model(tflite_file, [y_test_index], X_test, y_test)\n",
    "  for result in predictions:\n",
    "    print(\"Prediction: \", result)\n",
    "    print(\"Actual: \", y_test[y_test_index].argmax())\n",
    "    \n",
    "# Helper function to evaluate a TFLite model on all images\n",
    "def evaluate_cnn_model(tflite_file, X_test, y_test):\n",
    "  y_test_categories = y_test.argmax(axis=1)\n",
    "  \n",
    "  y_test_indexes = range(y_test.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, y_test_indexes, X_test, y_test)\n",
    "\n",
    "  accuracy = (np.sum(y_test_categories == predictions) * 100) / len(y_test)\n",
    "  \n",
    "  print(\"Number of correct predictions: \", np.sum(y_test_categories == predictions))\n",
    "  print(\"Number of wrong predictions: \", np.sum(y_test_categories != predictions))\n",
    "  print(\"Model accuracy is %.2f%% (Number of test samples=%d)\" % (accuracy, len(y_test_categories)))\n",
    "\n",
    "print(\"Evaluating CNN model using test data:\")\n",
    "evaluate_cnn_model('cnn_fullint_quantized.tflite', X_test, y_test)\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Evaluating CNN model using hidden data:\")\n",
    "evaluate_cnn_model('cnn_fullint_quantized.tflite', X_hidden, OHE_Y_hidden)\n",
    "print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Talos to check hyper parameter\n",
    "\n",
    "Reference: https://github.com/autonomio/talos/blob/master/examples/Hyperparameter%20Optimization%20with%20Keras%20for%20the%20Iris%20Prediction.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Dense, LeakyReLU, Conv1D, MaxPooling1D, UpSampling1D\n",
    "# from keras.optimizers import Adam, Nadam\n",
    "# from keras.callbacks import EarlyStopping\n",
    "# from keras.losses import mse as mse_loss\n",
    "# from keras import Sequential\n",
    "# from keras.layers import Dropout\n",
    "# from keras.regularizers import l1, l2\n",
    "\n",
    "# # Step 2: Split the data\n",
    "# X_train, X_test = train_test_split(data_healthy_vert_normalised[1], test_size=0.20, random_state=42)\n",
    "\n",
    "# def AR_talos_model(x_train, y_train, x_val, y_val, params):\n",
    "#     input_size = x_train.shape[1]\n",
    "\n",
    "#     input_layer = Input(shape=(input_size,))\n",
    "#     encoder_layer = Sequential([\n",
    "#         Dense(params['first_layer'], activation=params['activation']),\n",
    "#         Dropout(params['dropout']),\n",
    "#         Dense(params['second_layer'], activation=params['activation']),\n",
    "#         Dropout(params['dropout']),\n",
    "#         Dense(params['third_layer'], activation=params['activation'])\n",
    "#     ])\n",
    "\n",
    "#     decoder_layer = Sequential([\n",
    "#         Dense(params['third_layer'], activation=params['activation']),\n",
    "#         Dropout(params['dropout']),\n",
    "#         Dense(params['second_layer'], activation=params['activation']),\n",
    "#         Dropout(params['dropout']),\n",
    "#         Dense(input_size, activation='sigmoid')\n",
    "#     ])\n",
    "\n",
    "#     encoder_layer = encoder_layer(input_layer)\n",
    "#     decoder_layer = decoder_layer(encoder_layer)\n",
    "\n",
    "#     autoencoder = Model(inputs=input_layer, outputs=decoder_layer)\n",
    "\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, mode=\"auto\")\n",
    "\n",
    "#     # Step 4: Train the autoencoder\n",
    "#     autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "#     # Train the autoencoder with the EarlyStopping callback\n",
    "#     history = autoencoder.fit(\n",
    "#         x_train, x_train,\n",
    "#         epochs=params['epochs'],\n",
    "#         batch_size=params['batch_size'],\n",
    "#         validation_data=(x_val, x_val),\n",
    "#         callbacks=[early_stopping],\n",
    "#         verbose=1\n",
    "#     )\n",
    "    \n",
    "#     return history, autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating dict to use talos to do hyperparameter tuning\n",
    "# p = dict(\n",
    "# \tfirst_layer=[32, 48, 64],\n",
    "#     second_layer=[32, 48, 64],\n",
    "#     third_layer=[32, 48, 64],\n",
    "# \tactivation=['relu', 'elu'],\n",
    "# \tepochs=[50, 100, 200, 500],\n",
    "# \tbatch_size=[64, 128, 256, 512],\n",
    "#     dropout=[0, 0.01, 0.1, 0.15],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import talos\n",
    "\n",
    "# t = talos.Scan(X_train, \n",
    "#                X_train, \n",
    "#                params=p, \n",
    "#                model=AR_talos_model, \n",
    "#                experiment_name='AR_talos_model', \n",
    "#                fraction_limit=0.01, # Fraction of hyperparameter combinations to try\n",
    "#                print_params=True, \n",
    "#                round_limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experiment_name          AR_talos_model\n",
       "random_method          uniform_mersenne\n",
       "reduction_method                   None\n",
       "reduction_interval                   50\n",
       "reduction_window                     20\n",
       "reduction_threshold                 0.2\n",
       "reduction_metric                val_acc\n",
       "experiment_id              091923193350\n",
       "complete_time            09/19/23/20:39\n",
       "x_shape                    (39200, 100)\n",
       "y_shape                    (39200, 100)\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Acessing the results data frame\n",
    "# t.data.head()\n",
    "\n",
    "# # Accessing epoch entropy values for each round\n",
    "# t.learning_entropy\n",
    "\n",
    "# # Access the summary details\n",
    "# t.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_object = talos.Analyze(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>first_layer</th>\n",
       "      <th>second_layer</th>\n",
       "      <th>third_layer</th>\n",
       "      <th>activation</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09/19/23-193351</td>\n",
       "      <td>09/19/23-193519</td>\n",
       "      <td>88.645478</td>\n",
       "      <td>84</td>\n",
       "      <td>0.014765</td>\n",
       "      <td>0.012999</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>500</td>\n",
       "      <td>256</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/19/23-193520</td>\n",
       "      <td>09/19/23-193614</td>\n",
       "      <td>54.514668</td>\n",
       "      <td>50</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>elu</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/19/23-193615</td>\n",
       "      <td>09/19/23-193941</td>\n",
       "      <td>206.040746</td>\n",
       "      <td>200</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/19/23-193941</td>\n",
       "      <td>09/19/23-194000</td>\n",
       "      <td>18.943502</td>\n",
       "      <td>31</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>512</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/19/23-194000</td>\n",
       "      <td>09/19/23-194119</td>\n",
       "      <td>78.844273</td>\n",
       "      <td>200</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>elu</td>\n",
       "      <td>200</td>\n",
       "      <td>512</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09/19/23-194119</td>\n",
       "      <td>09/19/23-194152</td>\n",
       "      <td>32.272145</td>\n",
       "      <td>67</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>0.012196</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>elu</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>09/19/23-194152</td>\n",
       "      <td>09/19/23-194307</td>\n",
       "      <td>74.528511</td>\n",
       "      <td>97</td>\n",
       "      <td>0.011257</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>32</td>\n",
       "      <td>elu</td>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09/19/23-194307</td>\n",
       "      <td>09/19/23-200044</td>\n",
       "      <td>1057.296577</td>\n",
       "      <td>176</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>elu</td>\n",
       "      <td>500</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09/19/23-200044</td>\n",
       "      <td>09/19/23-200240</td>\n",
       "      <td>115.170355</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>elu</td>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>09/19/23-200240</td>\n",
       "      <td>09/19/23-200335</td>\n",
       "      <td>54.760252</td>\n",
       "      <td>50</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>elu</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>09/19/23-200335</td>\n",
       "      <td>09/19/23-200520</td>\n",
       "      <td>104.582355</td>\n",
       "      <td>155</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>500</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>09/19/23-200520</td>\n",
       "      <td>09/19/23-200643</td>\n",
       "      <td>83.585024</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010770</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>elu</td>\n",
       "      <td>100</td>\n",
       "      <td>512</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>09/19/23-200644</td>\n",
       "      <td>09/19/23-200954</td>\n",
       "      <td>190.079876</td>\n",
       "      <td>350</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>500</td>\n",
       "      <td>512</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>09/19/23-200955</td>\n",
       "      <td>09/19/23-201216</td>\n",
       "      <td>141.659447</td>\n",
       "      <td>95</td>\n",
       "      <td>0.009504</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>elu</td>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>09/19/23-201217</td>\n",
       "      <td>09/19/23-201624</td>\n",
       "      <td>247.379617</td>\n",
       "      <td>100</td>\n",
       "      <td>0.011658</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>09/19/23-201625</td>\n",
       "      <td>09/19/23-201652</td>\n",
       "      <td>27.427671</td>\n",
       "      <td>50</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>elu</td>\n",
       "      <td>50</td>\n",
       "      <td>512</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>09/19/23-201653</td>\n",
       "      <td>09/19/23-201726</td>\n",
       "      <td>33.396412</td>\n",
       "      <td>50</td>\n",
       "      <td>0.014485</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>512</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>09/19/23-201726</td>\n",
       "      <td>09/19/23-201808</td>\n",
       "      <td>41.584402</td>\n",
       "      <td>50</td>\n",
       "      <td>0.013439</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>elu</td>\n",
       "      <td>50</td>\n",
       "      <td>256</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>09/19/23-201808</td>\n",
       "      <td>09/19/23-201943</td>\n",
       "      <td>94.342646</td>\n",
       "      <td>100</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>09/19/23-201943</td>\n",
       "      <td>09/19/23-202149</td>\n",
       "      <td>125.878457</td>\n",
       "      <td>151</td>\n",
       "      <td>0.010487</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>elu</td>\n",
       "      <td>200</td>\n",
       "      <td>512</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>09/19/23-202149</td>\n",
       "      <td>09/19/23-202447</td>\n",
       "      <td>178.094283</td>\n",
       "      <td>104</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>0.008698</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>elu</td>\n",
       "      <td>500</td>\n",
       "      <td>128</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>09/19/23-202448</td>\n",
       "      <td>09/19/23-202545</td>\n",
       "      <td>56.896945</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>0.005918</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>elu</td>\n",
       "      <td>100</td>\n",
       "      <td>512</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>09/19/23-202545</td>\n",
       "      <td>09/19/23-202609</td>\n",
       "      <td>23.899556</td>\n",
       "      <td>16</td>\n",
       "      <td>0.017672</td>\n",
       "      <td>0.015925</td>\n",
       "      <td>48</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>09/19/23-202610</td>\n",
       "      <td>09/19/23-202828</td>\n",
       "      <td>138.752150</td>\n",
       "      <td>143</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.004648</td>\n",
       "      <td>48</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>elu</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>09/19/23-202829</td>\n",
       "      <td>09/19/23-202848</td>\n",
       "      <td>19.184461</td>\n",
       "      <td>24</td>\n",
       "      <td>0.017885</td>\n",
       "      <td>0.016105</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>09/19/23-202848</td>\n",
       "      <td>09/19/23-202922</td>\n",
       "      <td>34.156955</td>\n",
       "      <td>50</td>\n",
       "      <td>0.017626</td>\n",
       "      <td>0.015738</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>512</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>09/19/23-202923</td>\n",
       "      <td>09/19/23-203043</td>\n",
       "      <td>79.359371</td>\n",
       "      <td>55</td>\n",
       "      <td>0.017856</td>\n",
       "      <td>0.015794</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>09/19/23-203043</td>\n",
       "      <td>09/19/23-203211</td>\n",
       "      <td>87.731815</td>\n",
       "      <td>50</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>48</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>09/19/23-203211</td>\n",
       "      <td>09/19/23-203253</td>\n",
       "      <td>41.810018</td>\n",
       "      <td>69</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>512</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>09/19/23-203253</td>\n",
       "      <td>09/19/23-203518</td>\n",
       "      <td>145.077990</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>09/19/23-203519</td>\n",
       "      <td>09/19/23-203555</td>\n",
       "      <td>36.736925</td>\n",
       "      <td>15</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.016718</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>09/19/23-203556</td>\n",
       "      <td>09/19/23-203819</td>\n",
       "      <td>143.051149</td>\n",
       "      <td>138</td>\n",
       "      <td>0.005107</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>elu</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>09/19/23-203819</td>\n",
       "      <td>09/19/23-203919</td>\n",
       "      <td>60.167466</td>\n",
       "      <td>82</td>\n",
       "      <td>0.014937</td>\n",
       "      <td>0.012832</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>512</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>09/19/23-203920</td>\n",
       "      <td>09/19/23-203943</td>\n",
       "      <td>23.438585</td>\n",
       "      <td>15</td>\n",
       "      <td>0.017267</td>\n",
       "      <td>0.016230</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>128</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start              end     duration  round_epochs      loss  \\\n",
       "0   09/19/23-193351  09/19/23-193519    88.645478            84  0.014765   \n",
       "1   09/19/23-193520  09/19/23-193614    54.514668            50  0.005842   \n",
       "2   09/19/23-193615  09/19/23-193941   206.040746           200  0.004498   \n",
       "3   09/19/23-193941  09/19/23-194000    18.943502            31  0.017750   \n",
       "4   09/19/23-194000  09/19/23-194119    78.844273           200  0.003968   \n",
       "5   09/19/23-194119  09/19/23-194152    32.272145            67  0.015749   \n",
       "6   09/19/23-194152  09/19/23-194307    74.528511            97  0.011257   \n",
       "7   09/19/23-194307  09/19/23-200044  1057.296577           176  0.005154   \n",
       "8   09/19/23-200044  09/19/23-200240   115.170355           100  0.005068   \n",
       "9   09/19/23-200240  09/19/23-200335    54.760252            50  0.004884   \n",
       "10  09/19/23-200335  09/19/23-200520   104.582355           155  0.009058   \n",
       "11  09/19/23-200520  09/19/23-200643    83.585024           100  0.010770   \n",
       "12  09/19/23-200644  09/19/23-200954   190.079876           350  0.007784   \n",
       "13  09/19/23-200955  09/19/23-201216   141.659447            95  0.009504   \n",
       "14  09/19/23-201217  09/19/23-201624   247.379617           100  0.011658   \n",
       "15  09/19/23-201625  09/19/23-201652    27.427671            50  0.005583   \n",
       "16  09/19/23-201653  09/19/23-201726    33.396412            50  0.014485   \n",
       "17  09/19/23-201726  09/19/23-201808    41.584402            50  0.013439   \n",
       "18  09/19/23-201808  09/19/23-201943    94.342646           100  0.004692   \n",
       "19  09/19/23-201943  09/19/23-202149   125.878457           151  0.010487   \n",
       "20  09/19/23-202149  09/19/23-202447   178.094283           104  0.011836   \n",
       "21  09/19/23-202448  09/19/23-202545    56.896945           100  0.005955   \n",
       "22  09/19/23-202545  09/19/23-202609    23.899556            16  0.017672   \n",
       "23  09/19/23-202610  09/19/23-202828   138.752150           143  0.005382   \n",
       "24  09/19/23-202829  09/19/23-202848    19.184461            24  0.017885   \n",
       "25  09/19/23-202848  09/19/23-202922    34.156955            50  0.017626   \n",
       "26  09/19/23-202923  09/19/23-203043    79.359371            55  0.017856   \n",
       "27  09/19/23-203043  09/19/23-203211    87.731815            50  0.015491   \n",
       "28  09/19/23-203211  09/19/23-203253    41.810018            69  0.015384   \n",
       "29  09/19/23-203253  09/19/23-203518   145.077990           100  0.005776   \n",
       "30  09/19/23-203519  09/19/23-203555    36.736925            15  0.018109   \n",
       "31  09/19/23-203556  09/19/23-203819   143.051149           138  0.005107   \n",
       "32  09/19/23-203819  09/19/23-203919    60.167466            82  0.014937   \n",
       "33  09/19/23-203920  09/19/23-203943    23.438585            15  0.017267   \n",
       "\n",
       "    val_loss  first_layer  second_layer  third_layer activation  epochs  \\\n",
       "0   0.012999           64            64           64       relu     500   \n",
       "1   0.005081           64            32           64        elu      50   \n",
       "2   0.004513           48            48           64       relu     200   \n",
       "3   0.016012           32            32           64       relu     100   \n",
       "4   0.003961           48            48           48        elu     200   \n",
       "5   0.012196           32            32           32        elu     500   \n",
       "6   0.007977           48            48           32        elu     100   \n",
       "7   0.004473           32            48           48        elu     500   \n",
       "8   0.004493           32            64           48        elu     200   \n",
       "9   0.004145           48            48           48        elu      50   \n",
       "10  0.007938           64            32           32       relu     500   \n",
       "11  0.007123           32            48           64        elu     100   \n",
       "12  0.006513           48            48           32       relu     500   \n",
       "13  0.006384           64            64           48        elu     200   \n",
       "14  0.010597           64            64           64       relu     100   \n",
       "15  0.005550           64            32           64        elu      50   \n",
       "16  0.012569           64            64           48       relu      50   \n",
       "17  0.010005           32            32           32        elu      50   \n",
       "18  0.004700           64            64           48       relu     100   \n",
       "19  0.007107           48            48           48        elu     200   \n",
       "20  0.008698           64            32           32        elu     500   \n",
       "21  0.005918           64            32           32        elu     100   \n",
       "22  0.015925           48            32           48       relu     200   \n",
       "23  0.004648           48            32           64        elu     200   \n",
       "24  0.016105           32            32           48       relu     200   \n",
       "25  0.015738           64            48           48       relu      50   \n",
       "26  0.015794           64            32           64       relu     200   \n",
       "27  0.013679           48            32           64       relu      50   \n",
       "28  0.014086           48            64           48       relu     100   \n",
       "29  0.005762           64            32           48       relu     100   \n",
       "30  0.016718           32            48           64       relu     100   \n",
       "31  0.004487           48            64           32        elu     200   \n",
       "32  0.012832           64            64           64       relu     200   \n",
       "33  0.016230           32            48           64       relu     200   \n",
       "\n",
       "    batch_size  dropout  \n",
       "0          256     0.15  \n",
       "1          256     0.01  \n",
       "2          128     0.00  \n",
       "3          512     0.10  \n",
       "4          512     0.00  \n",
       "5          512     0.15  \n",
       "6          256     0.10  \n",
       "7          256     0.01  \n",
       "8          128     0.01  \n",
       "9          128     0.01  \n",
       "10         256     0.01  \n",
       "11         512     0.10  \n",
       "12         512     0.01  \n",
       "13         128     0.10  \n",
       "14          64     0.10  \n",
       "15         512     0.00  \n",
       "16         512     0.10  \n",
       "17         256     0.10  \n",
       "18         128     0.00  \n",
       "19         512     0.10  \n",
       "20         128     0.10  \n",
       "21         512     0.00  \n",
       "22         128     0.10  \n",
       "23         256     0.01  \n",
       "24         256     0.10  \n",
       "25         512     0.15  \n",
       "26         128     0.15  \n",
       "27          64     0.10  \n",
       "28         512     0.10  \n",
       "29          64     0.00  \n",
       "30          64     0.15  \n",
       "31         256     0.01  \n",
       "32         512     0.15  \n",
       "33         128     0.10  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access the dataframe with the results\n",
    "# analyze_object.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # get the number of rounds in the Scan\n",
    "# analyze_object.rounds()\n",
    "\n",
    "# # get the highest result for any metric\n",
    "# analyze_object.high('val_loss')\n",
    "\n",
    "# # get the round with the best result\n",
    "# analyze_object.rounds2high('loss')\n",
    "\n",
    "# # get the best paramaters\n",
    "# # analyze_object.best_params('val_loss', ['loss', 'val_loss'])\n",
    "\n",
    "# # get correlation for hyperparameters against a metric\n",
    "# # analyze_object.correlate('val_loss', ['loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # a regression plot for two dimensions \n",
    "# analyze_object.plot_regs('loss', 'val_loss')\n",
    "\n",
    "# # line plot\n",
    "# analyze_object.plot_line('val_loss')\n",
    "\n",
    "# # up to two dimensional kernel density estimator\n",
    "# analyze_object.plot_kde('val_loss')\n",
    "\n",
    "# # a simple histogram\n",
    "# analyze_object.plot_hist('val_loss', bins=50)\n",
    "\n",
    "# # heatmap correlation\n",
    "# analyze_object.plot_corr('val_loss', ['loss', 'val_loss'])\n",
    "\n",
    "# # a four dimensional bar grid\n",
    "# analyze_object.plot_bars('batch_size', 'val_loss', 'first_neuron', 'lr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36979ceee4f2a752b54cd2298f5ca5d95110725ea19573c088589be93a5c9bc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
