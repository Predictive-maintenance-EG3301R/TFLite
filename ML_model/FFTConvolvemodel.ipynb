{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference websites:\n",
    "* https://www.hackster.io/news/easy-tinyml-on-esp32-and-arduino-a9dbc509f26c\n",
    "* https://github.com/eloquentarduino/EloquentTinyML\n",
    "* https://github.com/atomic14/tensorflow-lite-esp32\n",
    "* https://github.com/eloquentarduino/tinymlgen\n",
    "* https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization\n",
    "* https://medium.com/mlearning-ai/optimizing-tflite-models-for-on-edge-machine-learning-for-efficiency-a-comparison-of-quantization-2c0123959cb6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to check out:\n",
    "* https://www.tensorflow.org/model_optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code below is used to generate the FFT TFLite Model \n",
    "* Healthy data: Own dataset\n",
    "* Unhealthy data: Online dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Read in only the vibration data from the Excel spreadsheet\n",
    "col_indices = [1,2,3]\n",
    "\n",
    "# Load the Excel spreadsheet\n",
    "normal_filename = glob.glob(\"C:/Users/jared/OneDrive - National University of Singapore/Y2/S2/3301R ML/Data_processing/Own_data/*.csv\")\n",
    "imbalance_data = glob.glob(\"C:/Users/jared/OneDrive - National University of Singapore/Y2/S2/3301R ML/Data_processing/Online_data/Machinary_Fault_dataset/imbalance/imbalance/35g/*.csv\")\n",
    "\n",
    "def dataReader(path_names, col_indices):\n",
    "    data_n = pd.DataFrame()\n",
    "    for i in path_names:\n",
    "        # Read only columns 0 to 6 which contains rotational frequency (1 column) + vibration data (6 columns)\n",
    "        low_data = pd.read_csv(i,header=None,usecols=col_indices) \n",
    "        data_n = pd.concat([data_n,low_data],ignore_index=True)\n",
    "    return data_n\n",
    "\n",
    "\n",
    "raw_data_norm = dataReader(normal_filename, col_indices)\n",
    "raw_data_norm.iloc[:, [1, 2]] = raw_data_norm.iloc[:, [2, 1]] # Swap columns for radial and tangential data\n",
    "raw_data_norm = raw_data_norm / 1000 # Convert to g\n",
    "\n",
    "raw_data_imbalance = dataReader(imbalance_data, col_indices)\n",
    "\n",
    "# Normalise the data\n",
    "def normalise(df):\n",
    "    df_normalized = df.apply(lambda x: (x - x.mean()) / x.std(), axis=0)\n",
    "    return df_normalized\n",
    "\n",
    "# Testing without normalisation\n",
    "# data_norm = raw_data_norm\n",
    "# data_imbalance = raw_data_imbalance\n",
    "\n",
    "# Testing with normalisation\n",
    "data_norm = normalise(raw_data_norm)\n",
    "data_imbalance = normalise(raw_data_imbalance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Checking if data is loaded in properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5098741 entries, 0 to 5098740\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   1       float64\n",
      " 1   2       float64\n",
      " 2   3       float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 116.7 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11250000 entries, 0 to 11249999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   1       float64\n",
      " 1   2       float64\n",
      " 2   3       float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 257.5 MB\n",
      "None\n",
      "          1         2         3\n",
      "0  1.620864 -0.940332  0.801613\n",
      "1  1.462940 -0.219391 -0.682770\n",
      "2  0.836181 -0.630328  0.642449\n",
      "3  0.327864  0.119451 -1.184484\n",
      "4 -0.229804  0.703413 -0.855775\n",
      "          1         2         3\n",
      "0 -1.508340 -0.250733 -0.164959\n",
      "1  0.791054  0.237543  0.107908\n",
      "2 -1.069483 -0.239004 -0.094518\n",
      "3  0.032145  0.158992  0.125634\n",
      "4 -0.093121 -0.092139  0.039919\n"
     ]
    }
   ],
   "source": [
    "print(data_norm.info())\n",
    "print(data_imbalance.info())\n",
    "\n",
    "print(data_norm.head())\n",
    "print(data_imbalance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Downsampling to reduce size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downSampler(data, a, b):\n",
    "    \"\"\"\n",
    "    data = data\n",
    "    a = start index\n",
    "    b = sampling rate\n",
    "    \"\"\"\n",
    "    x = b\n",
    "    downsampled_data = [data.iloc[a:b,:].sum()/x for i in range(int(len(data)/x))]\n",
    "    return pd.DataFrame(downsampled_data)\n",
    "\n",
    "# Create donwsampled datasets for excluding microphone data\n",
    "ds_data_norm = downSampler(data_norm, 0, 2500)\n",
    "ds_data_imbalance = downSampler(data_imbalance, 0, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Checking that data is downsampled properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2039, 3)\n",
      "(2250, 3)\n"
     ]
    }
   ],
   "source": [
    "print(ds_data_norm.shape)\n",
    "print(ds_data_imbalance.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Data processing. FFTConolve method is used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "def FFTConvolve(data):\n",
    "    autocorr = signal.fftconvolve(data,data[::-1],mode='full')\n",
    "    return pd.DataFrame(autocorr)\n",
    "\n",
    "# Create FFTConvolved datasets for excluding microphone data\n",
    "ds_data_norm_fftconvole = FFTConvolve(ds_data_norm)\n",
    "ds_data_imbalance_fftconvole = FFTConvolve(ds_data_imbalance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Checking that the data processing step is done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4077, 5)\n",
      "(4499, 5)\n"
     ]
    }
   ],
   "source": [
    "print(ds_data_norm_fftconvole.shape) # Check if data is FFTConvolved correctly\n",
    "print(ds_data_imbalance_fftconvole.shape) # Check if data is FFTConvolved correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Data labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4494</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8576 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "...  ..\n",
       "4494  1\n",
       "4495  1\n",
       "4496  1\n",
       "4497  1\n",
       "4498  1\n",
       "\n",
       "[8576 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up labels for both datasets\n",
    "y_0 = pd.DataFrame(np.zeros(int(len(ds_data_norm_fftconvole)),dtype=int))\n",
    "y_1 = pd.DataFrame(np.ones(int(len(ds_data_imbalance_fftconvole)),dtype=int))\n",
    "y = pd.concat([y_0,y_1],axis=0)\n",
    "y # Check if labels are set correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Preparing data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>0.821996</td>\n",
       "      <td>0.310837</td>\n",
       "      <td>0.129171</td>\n",
       "      <td>0.018867</td>\n",
       "      <td>0.003028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>0.657597</td>\n",
       "      <td>0.248670</td>\n",
       "      <td>0.103336</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0.002423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>0.493198</td>\n",
       "      <td>0.186502</td>\n",
       "      <td>0.077502</td>\n",
       "      <td>0.011320</td>\n",
       "      <td>0.001817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>0.328799</td>\n",
       "      <td>0.124335</td>\n",
       "      <td>0.051668</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>0.164399</td>\n",
       "      <td>0.062167</td>\n",
       "      <td>0.025834</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.000606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8576 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4\n",
       "0     0.000626  0.000637  0.000390  0.000116  0.000021\n",
       "1     0.001253  0.001273  0.000781  0.000232  0.000042\n",
       "2     0.001879  0.001910  0.001171  0.000349  0.000063\n",
       "3     0.002505  0.002546  0.001562  0.000465  0.000084\n",
       "4     0.003131  0.003183  0.001952  0.000581  0.000104\n",
       "...        ...       ...       ...       ...       ...\n",
       "8571  0.821996  0.310837  0.129171  0.018867  0.003028\n",
       "8572  0.657597  0.248670  0.103336  0.015093  0.002423\n",
       "8573  0.493198  0.186502  0.077502  0.011320  0.001817\n",
       "8574  0.328799  0.124335  0.051668  0.007547  0.001211\n",
       "8575  0.164399  0.062167  0.025834  0.003773  0.000606\n",
       "\n",
       "[8576 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x = pd.concat([ds_data_norm_fftconvole, ds_data_imbalance_fftconvole], ignore_index=True) # Concatenate all the data\n",
    "data_x # Check if data is concatenated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>0.821996</td>\n",
       "      <td>0.310837</td>\n",
       "      <td>0.129171</td>\n",
       "      <td>0.018867</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8572</th>\n",
       "      <td>0.657597</td>\n",
       "      <td>0.248670</td>\n",
       "      <td>0.103336</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8573</th>\n",
       "      <td>0.493198</td>\n",
       "      <td>0.186502</td>\n",
       "      <td>0.077502</td>\n",
       "      <td>0.011320</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>0.328799</td>\n",
       "      <td>0.124335</td>\n",
       "      <td>0.051668</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>0.164399</td>\n",
       "      <td>0.062167</td>\n",
       "      <td>0.025834</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8576 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4  0\n",
       "0     0.000626  0.000637  0.000390  0.000116  0.000021  0\n",
       "1     0.001253  0.001273  0.000781  0.000232  0.000042  0\n",
       "2     0.001879  0.001910  0.001171  0.000349  0.000063  0\n",
       "3     0.002505  0.002546  0.001562  0.000465  0.000084  0\n",
       "4     0.003131  0.003183  0.001952  0.000581  0.000104  0\n",
       "...        ...       ...       ...       ...       ... ..\n",
       "8571  0.821996  0.310837  0.129171  0.018867  0.003028  1\n",
       "8572  0.657597  0.248670  0.103336  0.015093  0.002423  1\n",
       "8573  0.493198  0.186502  0.077502  0.011320  0.001817  1\n",
       "8574  0.328799  0.124335  0.051668  0.007547  0.001211  1\n",
       "8575  0.164399  0.062167  0.025834  0.003773  0.000606  1\n",
       "\n",
       "[8576 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x_to_csv = pd.concat([data_x.reset_index(drop=True), y.reset_index(drop=True)], axis=1) # Concatenate data and labels\n",
    "data_x_to_csv # Check if data and labels are concatenated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_to_csv.to_csv('C:/Users/jared/Desktop/TFLite_FFTtestdata.csv',index=False,header=False) # Save to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, y, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 0.1114 - accuracy: 0.9918 - val_loss: 0.0325 - val_accuracy: 0.9907\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9977 - val_loss: 0.0202 - val_accuracy: 0.9922\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0153 - val_accuracy: 0.9953\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0133 - val_accuracy: 0.9961\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0111 - val_accuracy: 0.9969\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0094 - val_accuracy: 0.9969\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0084 - val_accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0086 - val_accuracy: 0.9969\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0091 - val_accuracy: 0.9969\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                192       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2434 (9.51 KB)\n",
      "Trainable params: 2434 (9.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\jared\\AppData\\Local\\Temp\\tmpuxid15o7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jared\\AppData\\Local\\Temp\\tmpuxid15o7\\assets\n",
      "c:\\Users\\jared\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11832"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "def representative_dataset():\n",
    "    for val in x_test:\n",
    "        yield [np.array(val, dtype=np.float32)]\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_shape=(5,)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax')) # Output layer needs to correspond to the number of classes for softmax\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=10, validation_split=0.2)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "FFTmodel = get_model()\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(FFTmodel)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"FFT_model_quantized.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Converting of model to C array (Run below line on bash)\n",
    "\n",
    "`xxd -i FFT_model_fullint_quantized.tflite > FFT_model_fullint_quantized.cc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the multiple models using different quantization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "161/161 [==============================] - 1s 3ms/step - loss: 0.1291 - accuracy: 0.9819 - val_loss: 0.0353 - val_accuracy: 0.9907\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 0.0188 - val_accuracy: 0.9938\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.0151 - val_accuracy: 0.9953\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0132 - val_accuracy: 0.9961\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0124 - val_accuracy: 0.9961\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0110 - val_accuracy: 0.9969\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0096 - val_accuracy: 0.9969\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0095 - val_accuracy: 0.9969\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0080 - val_accuracy: 0.9977\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0074 - val_accuracy: 0.9977\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 32)                192       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2434 (9.51 KB)\n",
      "Trainable params: 2434 (9.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\jared\\AppData\\Local\\Temp\\tmp72cpcw8r\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jared\\AppData\\Local\\Temp\\tmp72cpcw8r\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jared\\AppData\\Local\\Temp\\tmpanwq2smc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jared\\AppData\\Local\\Temp\\tmpanwq2smc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jared\\AppData\\Local\\Temp\\tmpt3sl6fh3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\jared\\AppData\\Local\\Temp\\tmpt3sl6fh3\\assets\n",
      "c:\\Users\\jared\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11904"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tinymlgen import port\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "early_stop = EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "## This method to get representative dataset results in lower accuracy, need to look into it\n",
    "# def representative_dataset():\n",
    "#     for data in tf.data.Dataset.from_tensor_slices(x_te).batch(1).take(x_test.size):\n",
    "#         yield [tf.dtypes.cast(data, tf.float32)]\n",
    "\n",
    "def representative_dataset():\n",
    "    for val in x_test:\n",
    "        yield [np.array(val, dtype=np.float32)]\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    # Initialising ANN model for 2 columns\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_shape=(5,)))\n",
    "    # model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    # model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "    # model.add(Dense(32, activation='relu',kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=10, validation_split=0.2)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "FFTmodel = get_model()\n",
    "\n",
    "# Dyanmic range quantization\n",
    "dyanmic_converter = tf.lite.TFLiteConverter.from_keras_model(FFTmodel)\n",
    "dyanmic_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "dyanmic_tflite_model = dyanmic_converter.convert()\n",
    "\n",
    "# Float16 quantization\n",
    "float16_converter = tf.lite.TFLiteConverter.from_keras_model(FFTmodel)\n",
    "float16_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "float16_converter.target_spec.supported_types = [tf.float16]\n",
    "float16_tflite_model = float16_converter.convert()\n",
    "\n",
    "# Full integer quantization\n",
    "# Only this one able to load on the ESP32 currently !!\n",
    "fullint_converter = tf.lite.TFLiteConverter.from_keras_model(FFTmodel)\n",
    "fullint_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "fullint_converter.representative_dataset = representative_dataset\n",
    "fullint_tflite_model = fullint_converter.convert()\n",
    "\n",
    "# Save the models to disk\n",
    "open(\"FFT_model_dynamic_quantized.tflite\", \"wb\").write(dyanmic_tflite_model)\n",
    "open(\"FFT_model_float16_quantized.tflite\", \"wb\").write(float16_tflite_model)\n",
    "open(\"FFT_model_fullint_quantized.tflite\", \"wb\").write(fullint_tflite_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the models built using different quantization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Baseline test accuracy: 99.95335936546326\n"
     ]
    }
   ],
   "source": [
    "# Testing the baseline model on the test dataset.\n",
    "\n",
    "# Evaluating the model on the test dataset.\n",
    "_, baseline_model_accuracy = FFTmodel.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "\n",
    "# Printing the baseline test accuracy in percentage.\n",
    "print('The Baseline test accuracy:', baseline_model_accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float 16 Quantized TFLite Model Test Accuracy: 99.95335820895522\n",
      "Full Integer Quantized TFLite Model Test Accuracy: 99.95335820895522\n",
      "Dynamic Quantized TFLite Model Test Accuracy: 99.95335820895522\n",
      "Baseline Keras Model Test Accuracy: 99.95335936546326\n"
     ]
    }
   ],
   "source": [
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    input_shape = input_details[0]['shape']\n",
    "    num_test_samples = len(x_test)\n",
    "\n",
    "    # Run predictions on every set in the \"test\" dataset.\n",
    "    prediction_y = []\n",
    "    for i in range(num_test_samples):\n",
    "\n",
    "        # Pre-processing the data to fit it with the model's input.\n",
    "        input_data = np.array(x_test.iloc[i,:], dtype=np.float32)\n",
    "        input_data = np.expand_dims(input_data, axis=0)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        prediction_y.append(output_data.argmax())\n",
    "\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction_y)):\n",
    "        if prediction_y[index] == y_test.iloc[index][0]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_y)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Passing the FP-16 TF Lite model to the interpreter.\n",
    "interpreter = tf.lite.Interpreter('FFT_model_float16_quantized.tflite')\n",
    "\n",
    "# Allocating tensors.\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Evaluating the model on the test dataset.\n",
    "test_accuracy_fp_16 = evaluate_model(interpreter)\n",
    "\n",
    "# Printing the test accuracy for the FP-16 quantized TFLite model and the baseline Keras model.\n",
    "print('Float 16 Quantized TFLite Model Test Accuracy:', test_accuracy_fp_16*100)\n",
    "\n",
    "# Testing the full integer quantized model on the test dataset.\n",
    "\n",
    "# Passing the full integer quantized TF Lite model to the interpreter.\n",
    "interpreter = tf.lite.Interpreter('FFT_model_fullint_quantized.tflite')\n",
    "\n",
    "# Allocating tensors.\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Evaluating the model on the test dataset.\n",
    "test_accuracy_int = evaluate_model(interpreter)\n",
    "\n",
    "# Printing the test accuracy for the full integer quantized TFLite model and the baseline Keras model.\n",
    "print('Full Integer Quantized TFLite Model Test Accuracy:', test_accuracy_int*100)\n",
    "\n",
    "# Testing the dynamic quantized model on the test dataset.\n",
    "\n",
    "# Passing the dynamic quantized TF Lite model to the interpreter.\n",
    "interpreter = tf.lite.Interpreter('FFT_model_dynamic_quantized.tflite')\n",
    "\n",
    "# Allocating tensors.\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Evaluating the model on the test dataset.\n",
    "test_accuracy_dynamic = evaluate_model(interpreter)\n",
    "\n",
    "# Printing the test accuracy for the dynamic quantized TFLite model and the baseline Keras model.\n",
    "print('Dynamic Quantized TFLite Model Test Accuracy:', test_accuracy_dynamic*100)\n",
    "\n",
    "# Printing the test accuracy for the baseline Keras model.\n",
    "print('Baseline Keras Model Test Accuracy:', baseline_model_accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current to-dos:\n",
    "* Find way to build FFTConvolve model without overfitting\n",
    "* Find way to do hyperparameters testing for models\n",
    "* Create template to test TF model and TFLite models quickly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
